{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "\n",
    "Given an array of integers, return indices of the two numbers such that they add up to a specific target.\n",
    "\n",
    "You may assume that each input would have exactly one solution, and you may not use the same element twice.\n",
    "\n",
    "Example:\n",
    "\n",
    "Given nums = [2, 7, 11, 15], target = 9,\n",
    "\n",
    "Because nums[0] + nums[1] = 2 + 7 = 9,\n",
    "return [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = {}\n",
    "nums = [157, 42, 55, 95, 100]\n",
    "target = 155\n",
    "def twoSum(nums, target):\n",
    "    for i, v in enumerate(nums):     # creates a list with indices and value\n",
    "      #  print(i, v)\n",
    "        diff = target - v           # find the difference between target and all the values of the list\n",
    "      #  print(diff)\n",
    "        if diff in dictionary:      # check if we do have that number in the dict\n",
    "            return [dictionary[diff], i]\n",
    " #      print(dictionary[v])\n",
    "        dictionary[v] = i\n",
    "        \n",
    "    return []\n",
    "#     if diff in dictionary:\n",
    "#         return [dictionary[temp], i]\n",
    "#     dictionary[v] = i\n",
    "twoSum(nums, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "n_H = 64\n",
    "for h in range(n_H):\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: zero_pad\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n",
    "    as illustrated in Figure 1.\n",
    "    \n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "    \n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n",
    "    \"\"\"\n",
    "    m, n_H, n_W, n_C = X.shape\n",
    "    #(≈ 1 line)\n",
    "    # X_pad = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), mode='constant', constant_values = (0,0))\n",
    "#     X_pad = np.pad(X, ((0,0), (n_H*pad,n_H*pad), (n_W*pad, n_W*pad), (0,0)), mode='constant', constant_values = (0,0))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_single_step\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n",
    "    of the previous layer.\n",
    "    \n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "    \n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    #(≈ 3 lines of code)\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    # s = None\n",
    "    # Sum over all entries of the volume s.\n",
    "    # Z = None\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    # Z = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    s = W*a_slice_prev\n",
    "    Z = np.sum(s)\n",
    "    Z = Z + float(b)\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_forward\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    # n_H = None\n",
    "    # n_W = None\n",
    "    n_H = int(n_H_prev - f + 2*pad/stride)+1\n",
    "    n_W = int(n_W_prev - f + 2*pad/stride)+1\n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    # Z = None\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    # A_prev_pad = None\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    # for i in range(None):               # loop over the batch of training examples\n",
    "        # a_prev_pad = None               # Select ith training example's padded activation\n",
    "        # for h in range(None):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            # vert_start = None\n",
    "            # vert_end = None\n",
    "            \n",
    "            # for w in range(None):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                # horiz_start = None\n",
    "                # horiz_end = None\n",
    "                \n",
    "                # for c in range(None):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    # a_slice_prev = None\n",
    "\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    # weights = None\n",
    "                    # biases = None\n",
    "                    # Z[i, h, w, c] = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        \n",
    "        print('A_prev_pad_shap: {}. a_prev_pad shape: {}'.format(A_prev_pad.shape, a_prev_pad.shape))\n",
    "        for h in range(n_H): # 7 for our current example\n",
    "            # a_slice_prev = a_prev[0:2,0:2,:]\n",
    "            vert_start = h*stride\n",
    "            print('vert_start:', vert_start)\n",
    "            vert_end = h+f # f is 3 so we will get 3 as teh end for the first loop\n",
    "            print('vert_end:',vert_end)\n",
    "            for w in range(n_W): # 9 for our case\n",
    "                horiz_start = w \n",
    "                horiz_end = w+f\n",
    "                for c in range(n_C): # number of channels is 4. \n",
    "                    print('prev_pad_shape: ', a_prev_pad.shape)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    print(a_slice_prev)\n",
    "                    print('a_slice_prev_shape: ', a_slice_prev.shape)\n",
    "                    # W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "                    print('W_shape: ', W[:, :, :, c].shape)\n",
    "                    weights = (np.multiply(a_slice_prev, W[:, :, :, c]))\n",
    "                    biases = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = np.sum(weights) + biases\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_forward\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, \n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "        \n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "#     print('n_H_prev_shape: {}, n_W_prev_shape: {}'.format(n_H_prev, n_W_prev))\n",
    "    # Retrieve dimensions from W's shape (≈1 li ne)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Compute the dimensions of the CONV output volume using the formula given above. \n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    # n_H = None\n",
    "    # n_W = None\n",
    "    n_H = int((n_H_prev - f + 2*pad)/stride)+1\n",
    "    n_W = int((n_W_prev - f + 2*pad)/stride)+1\n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    # Z = None\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    # A_prev_pad = None\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "#     print('A_prev_shape: ', A_prev.shape)\n",
    "#     print('A_prev_pad_shape: ', A_prev_pad.shape)\n",
    "    # for i in range(None):               # loop over the batch of training examples\n",
    "        # a_prev_pad = None               # Select ith training example's padded activation\n",
    "        # for h in range(None):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            # vert_start = None\n",
    "            # vert_end = None\n",
    "            \n",
    "            # for w in range(None):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                # horiz_start = None\n",
    "                # horiz_end = None\n",
    "                \n",
    "                # for c in range(None):   # loop over channels (= #filters) of the output volume\n",
    "                                        \n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    # a_slice_prev = None\n",
    "\n",
    "                    \n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    # weights = None\n",
    "                    # biases = None\n",
    "                    # Z[i, h, w, c] = None\n",
    "    # YOUR CODE STARTS HERE\n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i, :, :, :]\n",
    "        \n",
    "#         print('A_prev_pad_shape: {}. a_prev_pad shape: {}'.format(A_prev_pad, a_prev_pad))\n",
    "#         print('n_H: ', n_H)\n",
    "        for h in range(n_H): # 7 for our current example\n",
    "            # a_slice_prev = a_prev[0:2,0:2,:]\n",
    "            vert_start = h*stride\n",
    "#             print('vert_start:', vert_start)\n",
    "            vert_end = h*stride+f # f is 3 so we will get 3 as teh end for the first loop\n",
    "#             print('vert_end:',vert_end)\n",
    "            for w in range(n_W): # 9 for our case\n",
    "                horiz_start = w*stride \n",
    "                horiz_end = w*stride+f\n",
    "                for c in range(n_C): # number of channels is 4. \n",
    "#                     print('prev_pad_shape: ', a_prev_pad.shape)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "#                     a_slice_prev = a_prev_pad[horiz_start:horiz_end, vert_start:vert_end, :]\n",
    "#                     print(a_slice_prev)\n",
    "#                     print('a_slice_prev_shape: ', a_slice_prev.shape)\n",
    "                    # W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "#                     print('W_shape: ', W[:, :, :, c].shape)\n",
    "                    weights = (np.multiply(a_slice_prev, W[:, :, :, c]))\n",
    "                    biases = b[:, :, :, c]\n",
    "#                     print(\"i: {}, h: {}, w: {}, c:{}\".format(i, h, w, c))\n",
    "                    Z[i, h, w, c] = np.sum(weights[i]) + biases\n",
    "#                     print('Z: ', Z[i,h,w,c])\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.044736080182258275\n",
      "Z[0,2,1] =\n",
      " [-2.21606026  2.13392461 -1.88095355  1.28701971  3.02101408 -1.64625874\n",
      "  1.15957699  0.30061222]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conv_forward_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-182241fd5e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cache_conv[0][1][2][3] =\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_conv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mconv_forward_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_forward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_forward_test' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 7, 4)\n",
    "W = np.random.randn(3, 3, 4, 8)\n",
    "b = np.random.randn(1, 1, 1, 8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[0,2,1] =\\n\", Z[0, 2, 1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n",
    "\n",
    "conv_forward_test(conv_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'AbcDE'\n",
    "b = 'ABDE'\n",
    "\n",
    "for i in a:\n",
    "    for k in b:\n",
    "        if i == k:\n",
    "            print(\"YES\")\n",
    "        else:\n",
    "            print(\"YUGH\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the annual meeting of Board of Directors of Acme Inc. If everyone attending shakes hands exactly one time with every other attendee, how many handshakes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
